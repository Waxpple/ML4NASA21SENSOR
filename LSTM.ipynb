{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waxpple/ML4NASA21SENSOR/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_PnCRDFW7fH",
        "colab_type": "text"
      },
      "source": [
        "#REF:https://www.kaggle.com/nafisur/predictive-maintenance-using-lstm-on-sensor-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc1i32aQPMd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "2592f667-10bb-47cf-c1a3-2fbbfd7dd5a7"
      },
      "source": [
        "#get file from nasa\n",
        "!wget https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/train_FD001.txt\n",
        "!wget https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/RUL_FD001.txt\n",
        "!wget https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/test_FD001.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-06 20:18:40--  https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/train_FD001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3515356 (3.4M) [text/plain]\n",
            "Saving to: ‘train_FD001.txt.3’\n",
            "\n",
            "\rtrain_FD001.txt.3     0%[                    ]       0  --.-KB/s               \rtrain_FD001.txt.3   100%[===================>]   3.35M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-11-06 20:18:40 (38.6 MB/s) - ‘train_FD001.txt.3’ saved [3515356/3515356]\n",
            "\n",
            "--2019-11-06 20:18:41--  https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/RUL_FD001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 429 [text/plain]\n",
            "Saving to: ‘RUL_FD001.txt.3’\n",
            "\n",
            "RUL_FD001.txt.3     100%[===================>]     429  --.-KB/s    in 0s      \n",
            "\n",
            "2019-11-06 20:18:42 (73.6 MB/s) - ‘RUL_FD001.txt.3’ saved [429/429]\n",
            "\n",
            "--2019-11-06 20:18:43--  https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/test_FD001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2228855 (2.1M) [text/plain]\n",
            "Saving to: ‘test_FD001.txt.3’\n",
            "\n",
            "test_FD001.txt.3    100%[===================>]   2.12M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-11-06 20:18:43 (28.8 MB/s) - ‘test_FD001.txt.3’ saved [2228855/2228855]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en779XacPNx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d90152d1-a5a6-44a7-a616-8f029f563511"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers.core import Activation\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import scipy\n",
        "from scipy.stats import norm\n",
        "\n",
        "import boto3\n",
        "\n",
        "# get rid of deprecated warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn import linear_model\n",
        "\n",
        "\n",
        "import matplotlib as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "mlab.rcParams['figure.figsize']=(17,10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2Oj3Wk2Po-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4013a1cf-ab96-4f3a-894b-9244664bd25a"
      },
      "source": [
        "# get the training file and call its handler \"train\"\n",
        "train = pd.read_csv('train_FD001.txt',sep=\" \" ,header = None)             \n",
        "test = pd.read_csv('test_FD001.txt',sep =\" \",header = None)\n",
        "\n",
        "\n",
        "if train.empty:\n",
        "    raise Exception('No data found!')\n",
        "if test.empty:\n",
        "    raise Exception('No test found!')\n",
        "# remove some columns and add titles\n",
        "train.drop(train.columns[[26,27]],axis=1,inplace=True)\n",
        "test.drop(test.columns[[26,27]],axis=1,inplace=True)\n",
        "\n",
        "operational_columns = ['setting1','setting2','setting3']\n",
        "observational_columns = ['s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']\n",
        "\n",
        "train.columns = ['id','cycle'] + operational_columns + observational_columns \n",
        "test.columns = ['id','cycle'] + operational_columns + observational_columns \n",
        "\n",
        "#test = train\n",
        "print(train.head())\n",
        "print(test.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  cycle  setting1  setting2  setting3  ...  s17   s18    s19    s20      s21\n",
            "0   1      1   -0.0007   -0.0004     100.0  ...  392  2388  100.0  39.06  23.4190\n",
            "1   1      2    0.0019   -0.0003     100.0  ...  392  2388  100.0  39.00  23.4236\n",
            "2   1      3   -0.0043    0.0003     100.0  ...  390  2388  100.0  38.95  23.3442\n",
            "3   1      4    0.0007    0.0000     100.0  ...  392  2388  100.0  38.88  23.3739\n",
            "4   1      5   -0.0019   -0.0002     100.0  ...  393  2388  100.0  38.90  23.4044\n",
            "\n",
            "[5 rows x 26 columns]\n",
            "   id  cycle  setting1  setting2  setting3  ...  s17   s18    s19    s20      s21\n",
            "0   1      1    0.0023    0.0003     100.0  ...  392  2388  100.0  38.86  23.3735\n",
            "1   1      2   -0.0027   -0.0003     100.0  ...  393  2388  100.0  39.02  23.3916\n",
            "2   1      3    0.0003    0.0001     100.0  ...  393  2388  100.0  39.08  23.4166\n",
            "3   1      4    0.0042    0.0000     100.0  ...  391  2388  100.0  39.00  23.3737\n",
            "4   1      5    0.0014    0.0000     100.0  ...  390  2388  100.0  38.99  23.4130\n",
            "\n",
            "[5 rows x 26 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE1wHaj6Svx_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5f95376e-c6b8-4912-81b9-e60778392fcf"
      },
      "source": [
        "# prepare the dataset\n",
        "\n",
        "LOOKBACK_LENGTH = 50 # number of cycles in the past to analyse on a rolling basis\n",
        "DAYS_IN_ADVANCE = 30 # number of cycles we consider before the engine fail\n",
        "\n",
        "# get the \"truth\" data file to be used as the test dataset and call it \"truth\"\n",
        "\n",
        "##### TO BE COMPLETED #####                  \n",
        "truth = pd.read_csv('RUL_FD001.txt',sep=\" \" ,header = None) \n",
        "print(truth.head())\n",
        "truth.drop(truth.columns[[1]],axis=1,inplace=True)\n",
        "\n",
        "# for a given engine, RUL = cycle at failure - current cycle\n",
        "# we add this parameter as a column to the left of the training data table\n",
        "# then we drop the max column that becomes useless\n",
        "train.head()\n",
        "rul = pd.DataFrame(train.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id','max']\n",
        "train = train.merge(rul, on=['id'], how='left')\n",
        "\n",
        "train['RUL'] = train['max'] - train['cycle']\n",
        "train.drop('max', axis=1, inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0   1\n",
            "0  112 NaN\n",
            "1   98 NaN\n",
            "2   69 NaN\n",
            "3   82 NaN\n",
            "4   91 NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhlSTgsUP3AZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1acc854f-1740-4b01-95f5-ac416b545904"
      },
      "source": [
        "print(train.head())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  cycle  setting1  setting2  setting3  ...   s18    s19    s20      s21  RUL\n",
            "0   1      1   -0.0007   -0.0004     100.0  ...  2388  100.0  39.06  23.4190  191\n",
            "1   1      2    0.0019   -0.0003     100.0  ...  2388  100.0  39.00  23.4236  190\n",
            "2   1      3   -0.0043    0.0003     100.0  ...  2388  100.0  38.95  23.3442  189\n",
            "3   1      4    0.0007    0.0000     100.0  ...  2388  100.0  38.88  23.3739  188\n",
            "4   1      5   -0.0019   -0.0002     100.0  ...  2388  100.0  38.90  23.4044  187\n",
            "\n",
            "[5 rows x 27 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s05rHpl9S1W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rul = pd.DataFrame(test.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id','max']\n",
        "truth.columns = ['more']\n",
        "truth['id'] = truth.index + 1\n",
        "truth['max'] = rul['max'] + truth['more']\n",
        "truth.drop('more',axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JjfDQB5TMTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate test['RUL'] for test data using max and cycle\n",
        "\n",
        "test = test.merge(truth, on=['id'], how='left')\n",
        "\n",
        "test['RUL'] = test['max'] - test['cycle'] \n",
        "                 \n",
        "\n",
        "test.drop('max', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvPboOhyTq4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "14305271-1876-419e-87a1-97b280fe3aaf"
      },
      "source": [
        "df_train=train.copy()\n",
        "df_test=test.copy()\n",
        "period=DAYS_IN_ADVANCE\n",
        "df_train['label_bc'] = df_train['RUL'].apply(lambda x: 1 if x <= period else 0)\n",
        "df_test['label_bc'] = df_test['RUL'].apply(lambda x: 1 if x <= period else 0)\n",
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>RUL</th>\n",
              "      <th>label_bc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "      <td>191</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "      <td>190</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "      <td>189</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "      <td>188</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  ...    s20      s21  RUL  label_bc\n",
              "0   1      1   -0.0007   -0.0004  ...  39.06  23.4190  191         0\n",
              "1   1      2    0.0019   -0.0003  ...  39.00  23.4236  190         0\n",
              "2   1      3   -0.0043    0.0003  ...  38.95  23.3442  189         0\n",
              "3   1      4    0.0007    0.0000  ...  38.88  23.3739  188         0\n",
              "4   1      5   -0.0019   -0.0002  ...  38.90  23.4044  187         0\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UB8HB4tXLF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "7f741eba-f987-41fe-d7a6-aeb7c120b30e"
      },
      "source": [
        "df_test.head(100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>RUL</th>\n",
              "      <th>label_bc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.02</td>\n",
              "      <td>1585.29</td>\n",
              "      <td>1398.21</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.90</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9050.17</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.20</td>\n",
              "      <td>521.72</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8125.55</td>\n",
              "      <td>8.4052</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.86</td>\n",
              "      <td>23.3735</td>\n",
              "      <td>142</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.71</td>\n",
              "      <td>1588.45</td>\n",
              "      <td>1395.42</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.85</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>9054.42</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.50</td>\n",
              "      <td>522.16</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8139.62</td>\n",
              "      <td>8.3803</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.02</td>\n",
              "      <td>23.3916</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.46</td>\n",
              "      <td>1586.94</td>\n",
              "      <td>1401.34</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.11</td>\n",
              "      <td>2388.05</td>\n",
              "      <td>9056.96</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.50</td>\n",
              "      <td>521.97</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8130.10</td>\n",
              "      <td>8.4441</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.08</td>\n",
              "      <td>23.4166</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.44</td>\n",
              "      <td>1584.12</td>\n",
              "      <td>1406.42</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.07</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>9045.29</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.28</td>\n",
              "      <td>521.38</td>\n",
              "      <td>2388.05</td>\n",
              "      <td>8132.90</td>\n",
              "      <td>8.3917</td>\n",
              "      <td>0.03</td>\n",
              "      <td>391</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.3737</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.51</td>\n",
              "      <td>1587.19</td>\n",
              "      <td>1401.92</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.16</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>9044.55</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.31</td>\n",
              "      <td>522.15</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8129.54</td>\n",
              "      <td>8.4031</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4130</td>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0021</td>\n",
              "      <td>-0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.38</td>\n",
              "      <td>1592.50</td>\n",
              "      <td>1400.05</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.44</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9050.60</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.53</td>\n",
              "      <td>520.93</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>8127.71</td>\n",
              "      <td>8.4246</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.92</td>\n",
              "      <td>23.3800</td>\n",
              "      <td>179</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.83</td>\n",
              "      <td>1588.45</td>\n",
              "      <td>1405.40</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.81</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>9051.43</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.59</td>\n",
              "      <td>521.58</td>\n",
              "      <td>2388.15</td>\n",
              "      <td>8128.93</td>\n",
              "      <td>8.4287</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.81</td>\n",
              "      <td>23.3644</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>-0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.61</td>\n",
              "      <td>1581.11</td>\n",
              "      <td>1409.15</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.79</td>\n",
              "      <td>2388.10</td>\n",
              "      <td>9049.56</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.61</td>\n",
              "      <td>521.20</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8135.06</td>\n",
              "      <td>8.3918</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.87</td>\n",
              "      <td>23.1391</td>\n",
              "      <td>177</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.92</td>\n",
              "      <td>1587.40</td>\n",
              "      <td>1410.35</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.94</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>9050.03</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.57</td>\n",
              "      <td>521.28</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8136.31</td>\n",
              "      <td>8.4564</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.2953</td>\n",
              "      <td>176</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.28</td>\n",
              "      <td>1588.87</td>\n",
              "      <td>1410.34</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.36</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>9053.85</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.59</td>\n",
              "      <td>521.58</td>\n",
              "      <td>2388.13</td>\n",
              "      <td>8133.81</td>\n",
              "      <td>8.4204</td>\n",
              "      <td>0.03</td>\n",
              "      <td>394</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.2801</td>\n",
              "      <td>175</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  cycle  setting1  setting2  ...    s20      s21  RUL  label_bc\n",
              "0    1      1    0.0023    0.0003  ...  38.86  23.3735  142         0\n",
              "1    1      2   -0.0027   -0.0003  ...  39.02  23.3916  141         0\n",
              "2    1      3    0.0003    0.0001  ...  39.08  23.4166  140         0\n",
              "3    1      4    0.0042    0.0000  ...  39.00  23.3737  139         0\n",
              "4    1      5    0.0014    0.0000  ...  38.99  23.4130  138         0\n",
              "..  ..    ...       ...       ...  ...    ...      ...  ...       ...\n",
              "95   3     16    0.0021   -0.0000  ...  38.92  23.3800  179         0\n",
              "96   3     17    0.0003    0.0000  ...  38.81  23.3644  178         0\n",
              "97   3     18    0.0015   -0.0000  ...  38.87  23.1391  177         0\n",
              "98   3     19    0.0030   -0.0002  ...  39.00  23.2953  176         0\n",
              "99   3     20    0.0004   -0.0002  ...  38.88  23.2801  175         0\n",
              "\n",
              "[100 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR1nsaGlT6Ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_col_name=['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',\n",
        "                   's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "target_col_name='label_bc'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlaHhy_BUhRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc=preprocessing.MinMaxScaler()\n",
        "df_train[features_col_name]=sc.fit_transform(df_train[features_col_name])\n",
        "df_test[features_col_name]=sc.transform(df_test[features_col_name])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEOyYSzXUiF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    df_zeros=pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n",
        "    id_df=df_zeros.append(id_df,ignore_index=True)\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    lstm_array=[]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        lstm_array.append(data_array[start:stop, :])\n",
        "    return np.array(lstm_array)\n",
        "\n",
        "# function to generate labels\n",
        "def gen_label(id_df, seq_length, seq_cols,label):\n",
        "    df_zeros=pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n",
        "    id_df=df_zeros.append(id_df,ignore_index=True)\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    y_label=[]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        y_label.append(id_df[label][stop])\n",
        "    return np.array(y_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOd0i54tUwzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "248b19ce-8c75-474a-8351-f2888da7ef6e"
      },
      "source": [
        "seq_length=LOOKBACK_LENGTH\n",
        "seq_cols=features_col_name\n",
        "# generate X_train\n",
        "X_train=np.concatenate(list(list(gen_sequence(df_train[df_train['id']==id], seq_length, seq_cols)) for id in df_train['id'].unique()))\n",
        "print(X_train.shape)\n",
        "# generate y_train\n",
        "y_train=np.concatenate(list(list(gen_label(df_train[df_train['id']==id], 50, seq_cols,'label_bc')) for id in df_train['id'].unique()))\n",
        "print(y_train.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20531, 50, 24)\n",
            "(20531,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f04X3jiU6ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a78e365d-2a6e-4be1-ab20-6afaa282ba20"
      },
      "source": [
        "# generate X_test\n",
        "X_test=np.concatenate(list(list(gen_sequence(df_test[df_test['id']==id], seq_length, seq_cols)) for id in df_test['id'].unique()))\n",
        "print(X_test.shape)\n",
        "# generate y_test\n",
        "y_test=np.concatenate(list(list(gen_label(df_test[df_test['id']==id], 50, seq_cols,'label_bc')) for id in df_test['id'].unique()))\n",
        "print(y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12996, 50, 24)\n",
            "(12996,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s107uu8JU-yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "58f6b72c-bca3-4ead-f4e8-c58be79c2543"
      },
      "source": [
        "nb_features =X_train.shape[2]\n",
        "timestamp=seq_length\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(\n",
        "         input_shape=(timestamp, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 50, 100)           50000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 80,251\n",
            "Trainable params: 80,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpkOwFwhVAzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "5657c322-5c4d-4c35-b5ba-218c73e2ffeb"
      },
      "source": [
        "# fit the network\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=200, validation_split=0.05, verbose=1,\n",
        "          callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 19504 samples, validate on 1027 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "19504/19504 [==============================] - 29s 2ms/step - loss: 0.1996 - acc: 0.9235 - val_loss: 0.0967 - val_acc: 0.9601\n",
            "Epoch 2/10\n",
            "19504/19504 [==============================] - 28s 1ms/step - loss: 0.0842 - acc: 0.9659 - val_loss: 0.0699 - val_acc: 0.9640\n",
            "Epoch 3/10\n",
            "19504/19504 [==============================] - 29s 1ms/step - loss: 0.0707 - acc: 0.9713 - val_loss: 0.0525 - val_acc: 0.9708\n",
            "Epoch 4/10\n",
            "19504/19504 [==============================] - 29s 1ms/step - loss: 0.0647 - acc: 0.9720 - val_loss: 0.0453 - val_acc: 0.9805\n",
            "Epoch 5/10\n",
            "19504/19504 [==============================] - 29s 1ms/step - loss: 0.0660 - acc: 0.9721 - val_loss: 0.0424 - val_acc: 0.9825\n",
            "Epoch 6/10\n",
            "19504/19504 [==============================] - 29s 1ms/step - loss: 0.0590 - acc: 0.9753 - val_loss: 0.0332 - val_acc: 0.9922\n",
            "Epoch 7/10\n",
            "19504/19504 [==============================] - 29s 1ms/step - loss: 0.0543 - acc: 0.9753 - val_loss: 0.0382 - val_acc: 0.9844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf9c387ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjHjl79PVFF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ec4ef2a-ce56-4af2-bf74-13f323067561"
      },
      "source": [
        "# training metrics\n",
        "scores = model.evaluate(X_train, y_train, verbose=2, batch_size=200)\n",
        "print('Accurracy: {}'.format(scores[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurracy: 0.9771077925164516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFYa5pUoVwTo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e6c31d1e-e9be-44cd-bf14-e44fbdb3e6e5"
      },
      "source": [
        "y_pred=model.predict_classes(X_test)\n",
        "print('Accuracy of model on test data: ',accuracy_score(y_test,y_pred))\n",
        "print('precision_score of model on test data: ',precision_score(y_test,y_pred))\n",
        "print('recall_score of model on test data: ',recall_score(y_test,y_pred))\n",
        "print('Confusion Matrix: \\n',confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model on test data:  0.9897660818713451\n",
            "precision_score of model on test data:  0.9094650205761317\n",
            "recall_score of model on test data:  0.6656626506024096\n",
            "Confusion Matrix: \n",
            " [[12642    22]\n",
            " [  111   221]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYHv_qgUWR4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prob_failure(machine_id):\n",
        "    machine_df=df_test[df_test.id==machine_id]\n",
        "    machine_test=gen_sequence(machine_df,seq_length,seq_cols)\n",
        "    m_pred=model.predict(machine_test)\n",
        "    failure_prob=list(m_pred[-1]*100)[0]\n",
        "    return failure_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTUjBQ7bWShP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72908d56-8f61-44b7-996f-f920ec2ad296"
      },
      "source": [
        "machine_id=1\n",
        "print('Probability that machine will fail within 30 days: ',prob_failure(machine_id))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability that machine will fail within 30 days:  0.0016032687\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}