{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waxpple/ML4NASA21SENSOR/blob/master/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp6_9_Q62n4U",
        "colab_type": "code",
        "outputId": "7533edc9-95b9-45ee-fe7d-fb1ecf2d98a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "\n",
        "!wget https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/train_FD001.txt\n",
        "!wget https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/RUL_FD001.txt\n",
        "!wget https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/test_FD001.txt"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-23 18:34:01--  https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/train_FD001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3515356 (3.4M) [text/plain]\n",
            "Saving to: ‘train_FD001.txt’\n",
            "\n",
            "\rtrain_FD001.txt       0%[                    ]       0  --.-KB/s               \rtrain_FD001.txt     100%[===================>]   3.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-23 18:34:02 (32.6 MB/s) - ‘train_FD001.txt’ saved [3515356/3515356]\n",
            "\n",
            "--2019-10-23 18:34:03--  https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/RUL_FD001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 429 [text/plain]\n",
            "Saving to: ‘RUL_FD001.txt’\n",
            "\n",
            "RUL_FD001.txt       100%[===================>]     429  --.-KB/s    in 0s      \n",
            "\n",
            "2019-10-23 18:34:04 (147 MB/s) - ‘RUL_FD001.txt’ saved [429/429]\n",
            "\n",
            "--2019-10-23 18:34:06--  https://raw.githubusercontent.com/Waxpple/ML4NASA21SENSOR/master/test_FD001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2228855 (2.1M) [text/plain]\n",
            "Saving to: ‘test_FD001.txt’\n",
            "\n",
            "test_FD001.txt      100%[===================>]   2.12M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-23 18:34:06 (21.3 MB/s) - ‘test_FD001.txt’ saved [2228855/2228855]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkmls-1P4Bis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "295a1188-ce22-4d5d-8e49-d482fd6e2521"
      },
      "source": [
        "!rm RUL_FD001.txt.1 \n",
        "\n",
        "!rm test_FD001.txt \n",
        "!rm train_FD001.txt\n",
        "!rm train_FD001.txt.2\n",
        "!rm test_FD001.txt.1 \n",
        "!rm train_FD001.txt.1\n",
        "!ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2eyYX1EuQVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import os\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers.core import Activation\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import scipy\n",
        "from scipy.stats import norm\n",
        "\n",
        "import boto3\n",
        "\n",
        "# get rid of deprecated warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn import linear_model\n",
        "\n",
        "\n",
        "import matplotlib as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "mlab.rcParams['figure.figsize']=(17,10)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYPc5iLUuXrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar9fp1qYvOCD",
        "colab_type": "code",
        "outputId": "16ddbb15-e9df-45e5-929b-727c0cfb6853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "\n",
        "# get the training file and call its handler \"train\"\n",
        "train = pd.read_csv('train_FD001.txt',sep=\" \" ,header = None)             \n",
        "test2 = pd.read_csv('test_FD001.txt',sep = ' ',header = None)\n",
        "\n",
        "\n",
        "if train.empty:\n",
        "    raise Exception('No data found!')\n",
        "\n",
        "# remove some columns and add titles\n",
        "train.drop(train.columns[[26,27]],axis=1,inplace=True)\n",
        "test2.drop(test2.columns[[26,27]],axis=1,inplace=True)\n",
        "\n",
        "operational_columns = ['setting1','setting2','setting3']\n",
        "observational_columns = ['s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']\n",
        "\n",
        "train.columns = ['id','cycle'] + operational_columns + observational_columns \n",
        "test2.columns = ['id','cycle'] + operational_columns + observational_columns \n",
        "\n",
        "#test = train\n",
        "print(train.head())\n",
        "print(test2.head())\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  cycle  setting1  setting2  setting3  ...  s17   s18    s19    s20      s21\n",
            "0   1      1   -0.0007   -0.0004     100.0  ...  392  2388  100.0  39.06  23.4190\n",
            "1   1      2    0.0019   -0.0003     100.0  ...  392  2388  100.0  39.00  23.4236\n",
            "2   1      3   -0.0043    0.0003     100.0  ...  390  2388  100.0  38.95  23.3442\n",
            "3   1      4    0.0007    0.0000     100.0  ...  392  2388  100.0  38.88  23.3739\n",
            "4   1      5   -0.0019   -0.0002     100.0  ...  393  2388  100.0  38.90  23.4044\n",
            "\n",
            "[5 rows x 26 columns]\n",
            "   id  cycle  setting1  setting2  setting3  ...  s17   s18    s19    s20      s21\n",
            "0   1      1    0.0023    0.0003     100.0  ...  392  2388  100.0  38.86  23.3735\n",
            "1   1      2   -0.0027   -0.0003     100.0  ...  393  2388  100.0  39.02  23.3916\n",
            "2   1      3    0.0003    0.0001     100.0  ...  393  2388  100.0  39.08  23.4166\n",
            "3   1      4    0.0042    0.0000     100.0  ...  391  2388  100.0  39.00  23.3737\n",
            "4   1      5    0.0014    0.0000     100.0  ...  390  2388  100.0  38.99  23.4130\n",
            "\n",
            "[5 rows x 26 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q5X0U54vRUK",
        "colab_type": "code",
        "outputId": "daa6ade2-d608-4e3c-86a4-d54d6bcf1574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "\n",
        "\n",
        "# draw the histogram with the average cycle of failure \"mu\" using:\n",
        "# norm.fit and acipy.stats.norm.pdf\n",
        "# plt.hist\n",
        "\n",
        "##### TO BE COMPLETED #####                  \n",
        "Data1= train.groupby(['id'], sort=False,as_index=False)['cycle'].max()\n",
        "\n",
        "plt.hist(list(Data1['cycle']),bins=20,normed=False)\n",
        "(mu, std) = norm.fit(Data1['cycle'])\n",
        "plt.title('Histogram of Engine Failures: mean failure cycle = %.1f ' %(mu))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
            "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
            "  alternative=\"'density'\", removal=\"3.1\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9oAAAJOCAYAAABIl3+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1224x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRm2eqczvmRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare the dataset\n",
        "\n",
        "LOOKBACK_LENGTH = 10 # number of cycles in the past to analyse on a rolling basis\n",
        "DAYS_IN_ADVANCE = 30 # number of cycles we consider before the engine fail\n",
        "\n",
        "# get the \"truth\" data file to be used as the test dataset and call it \"truth\"\n",
        "\n",
        "##### TO BE COMPLETED #####                  \n",
        "truth = pd.read_csv('RUL_FD001.txt',sep=\" \" ,header = None) \n",
        "truth.drop(truth.columns[[1]],axis=1,inplace=True)\n",
        "\n",
        "# for a given engine, RUL = cycle at failure - current cycle\n",
        "# we add this parameter as a column to the left of the training data table\n",
        "# then we drop the max column that becomes useless\n",
        "train.head()\n",
        "rul = pd.DataFrame(train.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id','max']\n",
        "train = train.merge(rul, on=['id'], how='left')\n",
        "\n",
        "train['RUL'] = train['max'] - train['cycle']\n",
        "train.drop('max', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd2nffmsxZUz",
        "colab_type": "code",
        "outputId": "fc15dd0b-a294-4544-e436-9c839acf2289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# normalize the data in settings and sensors columns\n",
        "\n",
        "train['cycle_norm'] = train['cycle']\n",
        "cols_normalize = train.columns.difference(['id','cycle','RUL'])\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train[cols_normalize]),columns=cols_normalize,index=train.index)\n",
        "join_df = train[train.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "train = join_df.reindex(columns = train.columns)\n",
        "\n",
        "print(train.head(40))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    id  cycle  setting1  setting2  ...       s20       s21  RUL  cycle_norm\n",
            "0    1      1  0.459770  0.166667  ...  0.713178  0.724662  191    0.000000\n",
            "1    1      2  0.609195  0.250000  ...  0.666667  0.731014  190    0.002770\n",
            "2    1      3  0.252874  0.750000  ...  0.627907  0.621375  189    0.005540\n",
            "3    1      4  0.540230  0.500000  ...  0.573643  0.662386  188    0.008310\n",
            "4    1      5  0.390805  0.333333  ...  0.589147  0.704502  187    0.011080\n",
            "5    1      6  0.252874  0.416667  ...  0.651163  0.652720  186    0.013850\n",
            "6    1      7  0.557471  0.583333  ...  0.744186  0.667219  185    0.016620\n",
            "7    1      8  0.304598  0.750000  ...  0.643411  0.574979  184    0.019391\n",
            "8    1      9  0.545977  0.583333  ...  0.705426  0.707539  183    0.022161\n",
            "9    1     10  0.310345  0.583333  ...  0.627907  0.794256  182    0.024931\n",
            "10   1     11  0.603448  0.250000  ...  0.620155  0.807097  181    0.027701\n",
            "11   1     12  0.591954  0.666667  ...  0.713178  0.651477  180    0.030471\n",
            "12   1     13  0.390805  0.833333  ...  0.612403  0.526788  179    0.033241\n",
            "13   1     14  0.551724  0.500000  ...  0.806202  0.674399  178    0.036011\n",
            "14   1     15  0.396552  0.250000  ...  0.658915  0.629384  177    0.038781\n",
            "15   1     16  0.534483  0.916667  ...  0.643411  0.774372  176    0.041551\n",
            "16   1     17  0.511494  0.666667  ...  0.519380  0.604391  175    0.044321\n",
            "17   1     18  0.321839  0.416667  ...  0.581395  0.696631  174    0.047091\n",
            "18   1     19  0.683908  0.250000  ...  0.511628  0.624413  173    0.049861\n",
            "19   1     20  0.287356  0.583333  ...  0.689922  0.728804  172    0.052632\n",
            "20   1     21  0.431034  0.583333  ...  0.736434  0.574289  171    0.055402\n",
            "21   1     22  0.511494  0.500000  ...  0.604651  0.669705  170    0.058172\n",
            "22   1     23  0.695402  0.250000  ...  0.620155  0.776029  169    0.060942\n",
            "23   1     24  0.442529  0.750000  ...  0.666667  0.656448  168    0.063712\n",
            "24   1     25  0.632184  0.166667  ...  0.627907  0.738194  167    0.066482\n",
            "25   1     26  0.500000  0.666667  ...  0.558140  0.719000  166    0.069252\n",
            "26   1     27  0.431034  0.166667  ...  0.658915  0.763601  165    0.072022\n",
            "27   1     28  0.362069  0.916667  ...  0.674419  0.538387  164    0.074792\n",
            "28   1     29  0.568966  0.416667  ...  0.612403  0.642778  163    0.077562\n",
            "29   1     30  0.373563  0.500000  ...  0.705426  0.713615  162    0.080332\n",
            "30   1     31  0.580460  0.916667  ...  0.620155  0.609086  161    0.083102\n",
            "31   1     32  0.528736  0.250000  ...  0.682171  0.836371  160    0.085873\n",
            "32   1     33  0.258621  0.166667  ...  0.534884  0.630213  159    0.088643\n",
            "33   1     34  0.586207  0.416667  ...  0.519380  0.573046  158    0.091413\n",
            "34   1     35  0.517241  0.666667  ...  0.767442  0.721072  157    0.094183\n",
            "35   1     36  0.477011  0.333333  ...  0.558140  0.740956  156    0.096953\n",
            "36   1     37  0.477011  0.500000  ...  0.658915  0.747031  155    0.099723\n",
            "37   1     38  0.396552  0.333333  ...  0.713178  0.804474  154    0.102493\n",
            "38   1     39  0.327586  0.416667  ...  0.434109  0.656863  153    0.105263\n",
            "39   1     40  0.500000  0.166667  ...  0.542636  0.666529  152    0.108033\n",
            "\n",
            "[40 rows x 28 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6zhDHcNxd6K",
        "colab_type": "code",
        "outputId": "a1e2ddb7-5d33-4b6f-d13d-2f5d2e0b3549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# generate column max for test data\n",
        "\n",
        "rul = pd.DataFrame(test2.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id','max']\n",
        "truth.columns = ['more']\n",
        "truth['id'] = truth.index + 1\n",
        "truth['max'] = rul['max'] + truth['more']\n",
        "truth.drop('more',axis=1,inplace=True)\n",
        "\n",
        "print(truth.head())\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  max\n",
            "0   1  143\n",
            "1   2  147\n",
            "2   3  195\n",
            "3   4  188\n",
            "4   5  189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PW2iYtMxlPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate test['RUL'] for test data using max and cycle\n",
        "\n",
        "test = test2.merge(truth, on=['id'], how='left')\n",
        "\n",
        "test['RUL'] = test['max'] - test['cycle'] \n",
        "##### TO BE COMPLETED #####                  \n",
        "\n",
        "test.drop('max', axis=1, inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbEp_-zTxvUK",
        "colab_type": "code",
        "outputId": "14ed58d4-e033-47fc-a6ac-013890a5e3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(test.head(200))\n",
        "print(truth.head())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     id  cycle  setting1  setting2  setting3  ...   s18    s19    s20      s21  RUL\n",
            "0     1      1    0.0023    0.0003     100.0  ...  2388  100.0  38.86  23.3735  142\n",
            "1     1      2   -0.0027   -0.0003     100.0  ...  2388  100.0  39.02  23.3916  141\n",
            "2     1      3    0.0003    0.0001     100.0  ...  2388  100.0  39.08  23.4166  140\n",
            "3     1      4    0.0042    0.0000     100.0  ...  2388  100.0  39.00  23.3737  139\n",
            "4     1      5    0.0014    0.0000     100.0  ...  2388  100.0  38.99  23.4130  138\n",
            "5     1      6    0.0012    0.0003     100.0  ...  2388  100.0  38.91  23.3467  137\n",
            "6     1      7   -0.0000    0.0002     100.0  ...  2388  100.0  38.85  23.3952  136\n",
            "7     1      8    0.0006   -0.0000     100.0  ...  2388  100.0  39.05  23.3224  135\n",
            "8     1      9   -0.0036    0.0000     100.0  ...  2388  100.0  39.10  23.4521  134\n",
            "9     1     10   -0.0025   -0.0001     100.0  ...  2388  100.0  38.87  23.3820  133\n",
            "10    1     11    0.0007   -0.0004     100.0  ...  2388  100.0  39.06  23.3609  132\n",
            "11    1     12    0.0026    0.0003     100.0  ...  2388  100.0  39.11  23.3845  131\n",
            "12    1     13   -0.0056    0.0003     100.0  ...  2388  100.0  39.08  23.3677  130\n",
            "13    1     14    0.0017   -0.0004     100.0  ...  2388  100.0  39.03  23.4572  129\n",
            "14    1     15   -0.0003   -0.0003     100.0  ...  2388  100.0  39.04  23.3672  128\n",
            "15    1     16   -0.0018    0.0003     100.0  ...  2388  100.0  38.87  23.3484  127\n",
            "16    1     17    0.0014    0.0002     100.0  ...  2388  100.0  39.09  23.3409  126\n",
            "17    1     18    0.0035    0.0001     100.0  ...  2388  100.0  38.96  23.4481  125\n",
            "18    1     19    0.0029    0.0001     100.0  ...  2388  100.0  39.06  23.3809  124\n",
            "19    1     20    0.0011   -0.0001     100.0  ...  2388  100.0  39.00  23.3325  123\n",
            "20    1     21    0.0038   -0.0002     100.0  ...  2388  100.0  38.96  23.4025  122\n",
            "21    1     22    0.0012    0.0001     100.0  ...  2388  100.0  38.94  23.3770  121\n",
            "22    1     23    0.0009   -0.0000     100.0  ...  2388  100.0  39.10  23.3186  120\n",
            "23    1     24   -0.0006   -0.0001     100.0  ...  2388  100.0  38.94  23.3971  119\n",
            "24    1     25    0.0028   -0.0003     100.0  ...  2388  100.0  38.96  23.3785  118\n",
            "25    1     26    0.0047   -0.0005     100.0  ...  2388  100.0  38.77  23.3557  117\n",
            "26    1     27   -0.0007    0.0001     100.0  ...  2388  100.0  38.87  23.3931  116\n",
            "27    1     28    0.0022    0.0005     100.0  ...  2388  100.0  38.83  23.3502  115\n",
            "28    1     29    0.0014    0.0001     100.0  ...  2388  100.0  39.02  23.3621  114\n",
            "29    1     30   -0.0025    0.0004     100.0  ...  2388  100.0  39.09  23.4069  113\n",
            "..   ..    ...       ...       ...       ...  ...   ...    ...    ...      ...  ...\n",
            "170   3     91    0.0025    0.0000     100.0  ...  2388  100.0  38.96  23.3187  104\n",
            "171   3     92   -0.0048   -0.0003     100.0  ...  2388  100.0  38.97  23.2340  103\n",
            "172   3     93    0.0007    0.0004     100.0  ...  2388  100.0  38.80  23.1903  102\n",
            "173   3     94    0.0019    0.0002     100.0  ...  2388  100.0  38.75  23.3715  101\n",
            "174   3     95    0.0014   -0.0002     100.0  ...  2388  100.0  38.78  23.1833  100\n",
            "175   3     96   -0.0017   -0.0004     100.0  ...  2388  100.0  38.77  23.3385   99\n",
            "176   3     97   -0.0073   -0.0003     100.0  ...  2388  100.0  38.82  23.2457   98\n",
            "177   3     98   -0.0015    0.0002     100.0  ...  2388  100.0  38.99  23.2503   97\n",
            "178   3     99   -0.0007    0.0003     100.0  ...  2388  100.0  38.94  23.2226   96\n",
            "179   3    100    0.0007    0.0004     100.0  ...  2388  100.0  38.65  23.3360   95\n",
            "180   3    101    0.0019    0.0000     100.0  ...  2388  100.0  38.73  23.1899   94\n",
            "181   3    102    0.0001   -0.0000     100.0  ...  2388  100.0  38.76  23.1414   93\n",
            "182   3    103    0.0011   -0.0000     100.0  ...  2388  100.0  38.87  23.1864   92\n",
            "183   3    104    0.0004   -0.0005     100.0  ...  2388  100.0  38.87  23.2159   91\n",
            "184   3    105    0.0028   -0.0004     100.0  ...  2388  100.0  38.76  23.3094   90\n",
            "185   3    106    0.0024    0.0000     100.0  ...  2388  100.0  39.07  23.2566   89\n",
            "186   3    107    0.0004   -0.0002     100.0  ...  2388  100.0  38.70  23.2520   88\n",
            "187   3    108    0.0036   -0.0001     100.0  ...  2388  100.0  38.67  23.2485   87\n",
            "188   3    109   -0.0001    0.0004     100.0  ...  2388  100.0  38.71  23.2187   86\n",
            "189   3    110   -0.0008   -0.0000     100.0  ...  2388  100.0  38.88  23.2921   85\n",
            "190   3    111   -0.0038   -0.0002     100.0  ...  2388  100.0  38.97  23.2875   84\n",
            "191   3    112    0.0006    0.0004     100.0  ...  2388  100.0  38.61  23.3559   83\n",
            "192   3    113   -0.0015   -0.0005     100.0  ...  2388  100.0  38.90  23.2923   82\n",
            "193   3    114   -0.0033    0.0003     100.0  ...  2388  100.0  38.81  23.2768   81\n",
            "194   3    115    0.0023   -0.0001     100.0  ...  2388  100.0  38.85  23.2683   80\n",
            "195   3    116    0.0023   -0.0004     100.0  ...  2388  100.0  38.95  23.2440   79\n",
            "196   3    117    0.0022   -0.0005     100.0  ...  2388  100.0  38.98  23.2925   78\n",
            "197   3    118   -0.0019    0.0004     100.0  ...  2388  100.0  38.76  23.2100   77\n",
            "198   3    119    0.0057   -0.0003     100.0  ...  2388  100.0  38.78  23.1870   76\n",
            "199   3    120   -0.0049   -0.0004     100.0  ...  2388  100.0  38.69  23.1821   75\n",
            "\n",
            "[200 rows x 27 columns]\n",
            "   id  max\n",
            "0   1  143\n",
            "1   2  147\n",
            "2   3  195\n",
            "3   4  188\n",
            "4   5  189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kp39Qqt0CoI",
        "colab_type": "code",
        "outputId": "85fcf9dd-48fb-443a-bfd1-838221fd706a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "\n",
        "\n",
        "# normalize test data with MinMax normalization as above\n",
        "\n",
        "##### TO BE COMPLETED #####                  \n",
        "test['cycle_norm'] = test['cycle']\n",
        "cols_normalize = test.columns.difference(['id','cycle','RUL'])\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "norm_test_df = pd.DataFrame(min_max_scaler.fit_transform(test[cols_normalize]),columns=cols_normalize,index=test.index)\n",
        "join_df = test[test.columns.difference(cols_normalize)].join(norm_test_df)\n",
        "test = join_df.reindex(columns = test.columns)\n",
        "\n",
        "print(test.head(40))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    id  cycle  setting1  setting2  ...       s20       s21  RUL  cycle_norm\n",
            "0    1      1   0.65625  0.692308  ...  0.500000  0.620099  142    0.000000\n",
            "1    1      2   0.34375  0.230769  ...  0.645455  0.645718  141    0.003311\n",
            "2    1      3   0.53125  0.538462  ...  0.700000  0.681104  140    0.006623\n",
            "3    1      4   0.77500  0.461538  ...  0.627273  0.620382  139    0.009934\n",
            "4    1      5   0.60000  0.461538  ...  0.618182  0.676008  138    0.013245\n",
            "5    1      6   0.58750  0.692308  ...  0.545455  0.582166  137    0.016556\n",
            "6    1      7   0.51250  0.615385  ...  0.490909  0.650814  136    0.019868\n",
            "7    1      8   0.55000  0.461538  ...  0.672727  0.547771  135    0.023179\n",
            "8    1      9   0.28750  0.461538  ...  0.718182  0.731352  134    0.026490\n",
            "9    1     10   0.35625  0.384615  ...  0.509091  0.632130  133    0.029801\n",
            "10   1     11   0.55625  0.153846  ...  0.681818  0.602265  132    0.033113\n",
            "11   1     12   0.67500  0.692308  ...  0.727273  0.635669  131    0.036424\n",
            "12   1     13   0.16250  0.692308  ...  0.700000  0.611890  130    0.039735\n",
            "13   1     14   0.61875  0.153846  ...  0.654545  0.738570  129    0.043046\n",
            "14   1     15   0.49375  0.230769  ...  0.663636  0.611182  128    0.046358\n",
            "15   1     16   0.40000  0.692308  ...  0.509091  0.584572  127    0.049669\n",
            "16   1     17   0.60000  0.615385  ...  0.709091  0.573956  126    0.052980\n",
            "17   1     18   0.73125  0.538462  ...  0.590909  0.725690  125    0.056291\n",
            "18   1     19   0.69375  0.538462  ...  0.681818  0.630573  124    0.059603\n",
            "19   1     20   0.58125  0.384615  ...  0.627273  0.562067  123    0.062914\n",
            "20   1     21   0.75000  0.307692  ...  0.590909  0.661146  122    0.066225\n",
            "21   1     22   0.58750  0.538462  ...  0.572727  0.625053  121    0.069536\n",
            "22   1     23   0.56875  0.461538  ...  0.718182  0.542392  120    0.072848\n",
            "23   1     24   0.47500  0.384615  ...  0.572727  0.653503  119    0.076159\n",
            "24   1     25   0.68750  0.230769  ...  0.590909  0.627176  118    0.079470\n",
            "25   1     26   0.80625  0.076923  ...  0.418182  0.594904  117    0.082781\n",
            "26   1     27   0.46875  0.538462  ...  0.509091  0.647841  116    0.086093\n",
            "27   1     28   0.65000  0.846154  ...  0.472727  0.587120  115    0.089404\n",
            "28   1     29   0.60000  0.538462  ...  0.645455  0.603963  114    0.092715\n",
            "29   1     30   0.35625  0.769231  ...  0.709091  0.667374  113    0.096026\n",
            "30   1     31   0.47500  0.769231  ...  0.454545  0.594197  112    0.099338\n",
            "31   2      1   0.45625  0.769231  ...  0.627273  0.646709  146    0.000000\n",
            "32   2      2   0.44375  0.615385  ...  0.481818  0.502194  145    0.003311\n",
            "33   2      3   0.52500  0.692308  ...  0.645455  0.666667  144    0.006623\n",
            "34   2      4   0.66875  0.538462  ...  0.463636  0.756546  143    0.009934\n",
            "35   2      5   0.53750  0.153846  ...  0.454545  0.642746  142    0.013245\n",
            "36   2      6   0.46250  0.230769  ...  0.427273  0.471904  141    0.016556\n",
            "37   2      7   0.63125  0.461538  ...  0.400000  0.830573  140    0.019868\n",
            "38   2      8   0.60625  0.692308  ...  0.436364  0.408493  139    0.023179\n",
            "39   2      9   0.37500  0.692308  ...  0.363636  0.477849  138    0.026490\n",
            "\n",
            "[40 rows x 28 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeS37DMx-6kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# we want deux classes: 0 or 1 (no need for maintenance or maintenance needed)\n",
        "train['Y'] = np.where(train['RUL'] <= DAYS_IN_ADVANCE, 1, 0)\n",
        "test['Y'] = np.where(test['RUL'] <= DAYS_IN_ADVANCE, 1, 0)\n",
        "\n",
        "feature_columns = operational_columns + ['cycle_norm'] + observational_columns\n",
        "\n",
        "# train and test the model\n",
        "# First method: Logistic regression\n",
        "\n",
        "train_Y = train['Y']\n",
        "#train_rolling = train.groupby('id').apply(pd.DataFrame.rolling,LOOKBACK_LENGTH, min_periods=1)\n",
        "train_rolling = train.groupby('id')\n",
        "train_rolling = train_rolling.rolling(window=LOOKBACK_LENGTH, min_periods=1).mean()\n",
        "\n",
        "#print(train_rolling['Y'].tail(40))\n",
        "\n",
        "train_rolling = train_rolling.drop('cycle', axis=1)\n",
        "#train_rolling['Y'] = train_Y\n",
        "\n",
        "# Y is the variable to predict according to X\n",
        "\n",
        "X = train_rolling.drop(['Y','RUL'], axis=1)\n",
        "Y = train_rolling['Y'].fillna(0)\n",
        "Y = Y.astype('int')\n",
        "\n",
        "# create and \"fit\" or train the model with the training data using linear_model.LogisticRegression\n",
        "# call the model \"lr_model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dhEkHFa_gXz",
        "colab_type": "code",
        "outputId": "79f7fdaf-0c0d-4bbe-d7ed-af9600187764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn import preprocessing, linear_model\n",
        "\n",
        "lr_model =  linear_model.LogisticRegression()\n",
        "lr_model.fit(X, Y)\n",
        "\n",
        "# 印出係數\n",
        "print(lr_model.coef_)\n",
        "\n",
        "# 印出截距\n",
        "print(lr_model.intercept_ )\n",
        "predicted_classes = lr_model.predict(X)\n",
        "accuracy = accuracy_score(Y,predicted_classes)\n",
        "print(accuracy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.25637439e-03  5.50596629e-02  8.30286209e-01  0.00000000e+00\n",
            "   0.00000000e+00  3.85251551e+00  2.03872490e+00  2.43970722e+00\n",
            "   0.00000000e+00 -3.21819580e+00 -5.09576641e+00  2.83794030e+00\n",
            "   5.36118582e+00  0.00000000e+00  4.72458356e+00 -6.99650269e+00\n",
            "   2.87616886e+00  4.58714224e+00  2.95112335e+00  0.00000000e+00\n",
            "   2.56954836e+00  0.00000000e+00  0.00000000e+00 -2.88982404e+00\n",
            "  -4.97800644e+00 -4.23412116e+00]]\n",
            "[-3.25633879]\n",
            "0.971450729484756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRLpiWWRB3Px",
        "colab_type": "code",
        "outputId": "f9c8f871-cb87-497b-93d2-bc9d5023a62c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# prepare test data for prediction\n",
        "test_y = test['Y']\n",
        "all_test = test.groupby('id')\n",
        "all_test = all_test.rolling(window=LOOKBACK_LENGTH, min_periods=1).mean()\n",
        "all_test = all_test.drop('cycle', axis=1)\n",
        "#all_test['Y'] = test_y\n",
        "\n",
        "# define features to predict\n",
        "\n",
        "X_test_lr = all_test.drop(['Y','RUL'], axis=1)\n",
        "Y_test_lr = all_test['Y'].fillna(0)\n",
        "Y_test_lr = Y_test_lr.astype('int')\n",
        "\n",
        "# run the model for prediction\n",
        "predictions = list(lr_model.predict(X_test_lr))\n",
        "\n",
        "# return model evaluation metrics using accuracy_score\n",
        "print(accuracy_score(Y_test_lr, predictions))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9275351252290776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKEbArx6uVsq",
        "colab_type": "code",
        "outputId": "2708ecdd-eb3d-4c6d-bcca-e3670a776fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "\n",
        "\n",
        "##### TO BE COMPLETED #####                  \n",
        "\n",
        "\n",
        "cm = confusion_matrix(Y_test_lr,predictions)\n",
        "print('\\nConfusion Matrix for LR:\\n', cm)\n",
        "#print('\\nAccuracy: {}'.format(logistic_acc))\n",
        "#print('\\nPrecision: {}'.format(logistic_prec))\n",
        "#print('\\nRecall: {}'.format(logistic_recall))\n",
        "\n",
        "# Applying the model to a new data point\n",
        "\n",
        "print(\"\\n\\nApplying LR to engine #31...\\n\")\n",
        "engine_number = 31\n",
        "new_engine = test[test['id'] == engine_number]\n",
        "#X_new_engine, Y_new_engine = flip_data(df=new_engine, feature_columns=feature_columns, lookback_length=LOOKBACK_LENGTH )\n",
        "\n",
        "Y_predicted_new_engine_lr = lr_model.predict(X_test_lr[X_test_lr['id'] == engine_number])\n",
        "\n",
        "max_cycles = new_engine.shape[0]\n",
        "cycles = range(LOOKBACK_LENGTH,(max_cycles-1),1)\n",
        "\n",
        "new_engine_results = pd.DataFrame({'Cycle':cycles, 'LogisticR' : Y_predicted_new_engine_lr[(LOOKBACK_LENGTH+1):]})\n",
        "\n",
        "print(new_engine_results.tail(30))\n",
        "\n",
        "# print the predicted failure day\n",
        "\n",
        "##### TO BE COMPLETED #####                  \n",
        "\n",
        "# make the user enter which engine number is to be predicted\n",
        "\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Confusion Matrix for LR:\n",
            " [[12006   948]\n",
            " [    1   141]]\n",
            "\n",
            "\n",
            "Applying LR to engine #31...\n",
            "\n",
            "     Cycle  LogisticR\n",
            "155    165          1\n",
            "156    166          1\n",
            "157    167          1\n",
            "158    168          1\n",
            "159    169          1\n",
            "160    170          1\n",
            "161    171          1\n",
            "162    172          1\n",
            "163    173          1\n",
            "164    174          1\n",
            "165    175          1\n",
            "166    176          1\n",
            "167    177          1\n",
            "168    178          1\n",
            "169    179          1\n",
            "170    180          1\n",
            "171    181          1\n",
            "172    182          1\n",
            "173    183          1\n",
            "174    184          1\n",
            "175    185          1\n",
            "176    186          1\n",
            "177    187          1\n",
            "178    188          1\n",
            "179    189          1\n",
            "180    190          1\n",
            "181    191          1\n",
            "182    192          1\n",
            "183    193          1\n",
            "184    194          1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}